{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702bd2f3-8744-4943-b69d-6198a0c51760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"./stat679final/data/metadata/train_metadata.csv\")\n",
    "df_test = pd.read_csv(\"./stat679final/data/metadata/test_metadata.csv\")\n",
    "X_train, y_train = df_train.iloc[:, 0:6], df_train[\"class\"]\n",
    "# X, y = df.iloc[:, 0:6], df[\"class\"]\n",
    "X_test, y_test = df_test.iloc[:, 0:6], df_test[\"class\"]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the individual classifiers\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "lr_clf = LogisticRegression(max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1217a712-bde1-4ce0-b704-e6cbb5846a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard\n",
      "soft\n",
      "Hard Voting Accuracy: 0.9785478547854786\n",
      "Soft Voting Accuracy: 0.9807480748074807\n"
     ]
    }
   ],
   "source": [
    "# svm_clf = SVC(probability=True)  # Enable probability for soft voting\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('knn', knn_clf), ('dt', tree_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[('knn', knn_clf), ('dt', tree_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the classifiers\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "print(\"hard\")\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "print(\"soft\")\n",
    "# Make predictions and evaluate\n",
    "y_pred_hard = voting_clf_hard.predict(X_test)\n",
    "y_pred_soft = voting_clf_soft.predict(X_test)\n",
    "\n",
    "print(\"Hard Voting Accuracy:\", accuracy_score(y_test, y_pred_hard))\n",
    "print(\"Soft Voting Accuracy:\", accuracy_score(y_test, y_pred_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102660a4-958a-47aa-8820-666b1953cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class PyTorchClassifierWrapper:\n",
    "    def __init__(self, model, device='cpu'):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def predict_proba(self, dataloader):\n",
    "        # Ensure the model is in evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # List to hold all batch probabilities\n",
    "        all_probabilities = []\n",
    "\n",
    "        # Loop over all batches in the dataloader\n",
    "        for X_batch in dataloader:\n",
    "            images, label = X_batch\n",
    "            # Transfer batch to the device (GPU or CPU)\n",
    "            images = images.to(self.device)\n",
    "\n",
    "            # Disable gradient computation\n",
    "            with torch.no_grad():\n",
    "                if torch.all(images.eq(-1)).item():\n",
    "                    probabilities = torch.tensor([[ 0, 0, 0]])\n",
    "                    #print('un')\n",
    "                else: \n",
    "                    outputs = self.model(images)\n",
    "\n",
    "                    # Apply softmax to compute probabilities\n",
    "                    probabilities = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Move probabilities to CPU and convert to numpy\n",
    "            probabilities = probabilities.cpu().numpy()\n",
    "            \n",
    "            # Append batch probabilities to list\n",
    "            all_probabilities.append(probabilities)\n",
    "\n",
    "        # Concatenate all batch probabilities into a single array\n",
    "        all_probabilities = np.concatenate(all_probabilities, axis=0)\n",
    "        \n",
    "        return all_probabilities\n",
    "    def predict(self,dataloader):\n",
    "        all_predictions = []\n",
    "        for X_batch in dataloader:\n",
    "            images, label = X_batch\n",
    "            # Transfer batch to the device (GPU or CPU)\n",
    "            images = images.to(self.device)\n",
    "\n",
    "            # Disable gradient computation\n",
    "            with torch.no_grad():\n",
    "                if torch.all(images.eq(-1)).item():\n",
    "                    predictions = torch.tensor([[0, 0, 0]])\n",
    "                    print(1)\n",
    "                else: \n",
    "                    outputs = self.model(images)\n",
    "                    predictions = outputs.argmax(dim=-1)\n",
    "\n",
    "                    # Convert indices to one-hot encoded tensor\n",
    "                    #predictions = F.one_hot(max_indices, num_classes=outputs.shape[-1]).cpu().numpy()\n",
    "                    #print(1)\n",
    "                    # Move probabilities to CPU and convert to numpy\n",
    "\n",
    "                    # Append batch probabilities to list\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "        # Concatenate all batch probabilities into a single array\n",
    "        all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "        \n",
    "        return all_predictions\n",
    "\n",
    "    \n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input channels = 3 (RGB), 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)  # Adjusted for 64x64 input images\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)  # Output 3 classes: STAR, QSO, GALAXY\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 13 * 13)  # Flatten the tensor for the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e65a3de-0b46-4c75-b00c-fa981aa07d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=2704, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
      ")\n",
      "it is a galaxy\n",
      "tensor([[ 3.7507, -0.3346, -4.1034]])\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('./stat679final/model/CNN/SimpleCNN_state_dict.pth'))\n",
    "model.eval()  \n",
    "print(model)\n",
    "\n",
    "\n",
    "# Define the same transformation as during the training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Example resize, adjust to your model's input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('./stat679final/data/GALAXY/GALAXY_1.jpg')\n",
    "image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "with torch.no_grad():  # Turn off gradients for inference\n",
    "    output = model(image)\n",
    "    # Assuming classification: get the predicted class (the index of the max log-probability)\n",
    "    predicted_class = torch.argmax(output, dim=1)\n",
    "    if predicted_class.item()+1 == 1:\n",
    "      print(\"it is a galaxy\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc60b7ec-4d7b-49df-bfc3-adb002422a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=2704, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
      ")\n",
      "it is a galaxy\n",
      "tensor([0])\n",
      "tensor([[ 2.8297, -1.9385, -1.7206]])\n"
     ]
    }
   ],
   "source": [
    "model_spec = SimpleCNN()\n",
    "model_spec.load_state_dict(torch.load('./stat679final/model/CNN/spec_state_dict.pth'))\n",
    "model_spec.eval()  \n",
    "print(model_spec)\n",
    "\n",
    "\n",
    "# Define the same transformation as during the training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Example resize, adjust to your model's input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('./data_spec/GALAXY_spec/GALAXY_1.jpg').convert('RGB')\n",
    "image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "with torch.no_grad():  # Turn off gradients for inference\n",
    "    output = model_spec(image)\n",
    "    # Assuming classification: get the predicted class (the index of the max log-probability)\n",
    "    predicted_class = torch.argmax(output, dim=1)\n",
    "    if predicted_class.item()+1 == 1:\n",
    "        print(\"it is a galaxy\")\n",
    "    print(output.argmax(dim=-1))\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe87412-983b-4a92-844e-cc54a2a1c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(models, datasets):\n",
    "    \"\"\"\n",
    "    对多个模型的预测概率进行平均，返回最终预测类别。\n",
    "    :param models: 包含四个模型的列表\n",
    "    :param datasets: 每个模型对应的测试数据集列表\n",
    "    :return: 最终的预测类别数组\n",
    "    \"\"\"\n",
    "    # 收集所有模型的预测概率\n",
    "    proba_lists = [model.predict_proba(data) for model, data in zip(models, datasets)]\n",
    "\n",
    "    # 计算平均预测概率\n",
    "    avg_proba = np.mean(proba_lists, axis=0)\n",
    "\n",
    "    # 选择平均概率最高的类别作为最终预测\n",
    "    final_predictions = np.argmax(avg_proba, axis=1)\n",
    "    return final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d64f48-950a-4e21-95ee-a67cacbaa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def weighted_hard_voting(models, datasets, weights):\n",
    "    \"\"\"\n",
    "    对多个模型的预测类别进行加权硬投票，返回最终预测类别。\n",
    "    :param models: 包含四个模型的列表\n",
    "    :param datasets: 每个模型对应的测试数据集列表\n",
    "    :param weights: 每个模型在训练集上的准确率作为权重，列表形式\n",
    "    :return: 最终的预测类别数组\n",
    "    \"\"\"\n",
    "    # 收集所有模型的预测类别\n",
    "    predictions = [model.predict(data) for model, data in zip(models, datasets)]\n",
    "    #print(predictions.shape)\n",
    "    #print(datasets[3].shape[0])\n",
    "    # 转换预测为权重计票矩阵\n",
    "    weighted_votes = np.zeros((datasets[3].shape[0], np.max(predictions) + 1))  # 假设类别从0开始\n",
    "\n",
    "    # 累加每个模型的预测权重到对应类别\n",
    "    for prediction, weight in zip(predictions, weights):\n",
    "        for i, pred in enumerate(prediction):\n",
    "            weighted_votes[i, pred] += weight\n",
    "\n",
    "    # 选择权重计票最高的类别作为最终预测\n",
    "    final_predictions = np.argmax(weighted_votes, axis=1)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd370ae6-57a4-481f-ba32-381943e3548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model1 = PyTorchClassifierWrapper(model, device='cpu')\n",
    "pytorch_model2 = PyTorchClassifierWrapper(model_spec, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95f6aa9b-ab7c-45e4-9958-eb893f928ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# knn = KNeighborsClassifier()\n",
    "\n",
    "# # Create a dictionary with the values of n_neighbors\n",
    "# param_grid = {'n_neighbors': range(1, 21)}\n",
    "\n",
    "# # Setup the grid search\n",
    "# grid_search = GridSearchCV(knn, param_grid, cv=5)  # 5-fold cross-validation\n",
    "\n",
    "# # Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Best parameter and score\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3a754c0-3e01-4493-8f07-12b92e09264c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Define the model\n",
    "# log_reg = LogisticRegression()\n",
    "\n",
    "# # Define a grid of parameters\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10],\n",
    "#     'penalty': ['none', 'l2'],\n",
    "#     'max_iter': [2000, 3000, 4000]  # Adding different values for max_iter\n",
    "# }\n",
    "\n",
    "# # Setup the grid search\n",
    "# grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# # Fit grid search\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Print the best parameters and the best score\n",
    "# print(\"Best parameters:\", grid_search.best_params_)\n",
    "# print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d4f473-acaa-45f7-9e81-b36b136cbdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=2000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "tree_clf = DecisionTreeClassifier(max_depth=4)\n",
    "lr_clf = LogisticRegression(max_iter=2000)\n",
    "\n",
    "knn_clf.fit(X_train, y_train)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bef285c-2374-4459-8110-3c5ba4ab832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "test_image = pd.read_csv(\"./stat679final/data/rnk_test.csv\")\n",
    "#test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3da641a6-b4d6-49d3-839f-1675752ec37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to ensure all images are the same size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize images\n",
    "])\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels  # Store the labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.labels[idx]  # Get the label for the current image\n",
    "        if self.transform:\n",
    "            try:\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "                image = self.transform(image)\n",
    "                return image, label  # Return both the image and the label\n",
    "            except IOError:\n",
    "                return torch.zeros([3,64,64]), label\n",
    "# Assuming 'class' column in image_paths_df contains labels\n",
    "img_paths = test_image['image']\n",
    "labels = test_image['class']  # Load labels from the dataframe\n",
    "\n",
    "# Initialize dataset with paths and labels\n",
    "custom_dataset = CustomImageDataset(img_paths, labels, transform=transform)\n",
    "custom_data_loader = DataLoader(custom_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "img_paths_spec = test_image['spec']\n",
    "labels = test_image['class']  # Load labels from the dataframe\n",
    "\n",
    "# Initialize dataset with paths and labels\n",
    "custom_dataset_spec = CustomImageDataset(img_paths_spec, labels, transform=transform)\n",
    "custom_data_loader_spec = DataLoader(custom_dataset_spec, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9f8e0dc-138d-4b53-8a63-4e67e200d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [pytorch_model1,pytorch_model2, knn_clf,tree_clf,lr_clf]\n",
    "datasets = [custom_data_loader,custom_data_loader_spec,X_test,X_test,X_test]\n",
    "# do soft voting\n",
    "soft_predictions = soft_voting(models, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "518a0fcb-1088-4aba-9dbf-f233990d4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.918, 0.9914,0.968,0.9770,0.9699]\n",
    "models = [pytorch_model1,pytorch_model2, knn_clf, tree_clf,lr_clf]\n",
    "datasets = [custom_data_loader,custom_data_loader_spec,X_test,X_test,X_test]\n",
    "# hard voting\n",
    "hard_predictions = weighted_hard_voting(models, datasets,weights)\n",
    "#predictions = [model.predict(data) for model, data in zip(models, datasets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a86beb9-c0b4-4dfa-9844-baebf61eb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_image = pytorch_model1.predict(dataloader=custom_data_loader)\n",
    "CNN_spec = pytorch_model2.predict(dataloader=custom_data_loader_spec)\n",
    "knn_pred = knn_clf.predict(X_test)\n",
    "tree_pred = tree_clf.predict(X_test)\n",
    "lr_pred = lr_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ccfabb6-b01f-47ef-870e-858c462361ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of CNN image classifier 0.9173417341734174\n",
      "The accuracy of CNN spec classifier 0.9173417341734174\n",
      "The accuracy of knn classifier 0.968046804680468\n",
      "The accuracy of tree classifier 0.9743974397439744\n",
      "The accuracy of logistic regression classifier 0.96999699969997\n",
      "The accuracy of Soft Voting classifier 0.9897489748974897\n",
      "The accuracy of Hard Voting classifier 0.9862986298629863\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of CNN image classifier',(CNN_image == y_test).sum()/len(y_test))\n",
    "print('The accuracy of CNN spec classifier',(CNN_image == y_test).sum()/len(y_test))\n",
    "print('The accuracy of knn classifier',(knn_pred == y_test).sum()/len(y_test))\n",
    "print('The accuracy of tree classifier',(tree_pred == y_test).sum()/len(y_test))\n",
    "print('The accuracy of logistic regression classifier',(lr_pred == y_test).sum()/len(y_test))\n",
    "print('The accuracy of Soft Voting classifier',(soft_predictions == y_test).sum()/len(y_test))\n",
    "print('The accuracy of Hard Voting classifier',(hard_predictions == y_test).sum()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1498d5-cdd5-499f-aa72-c832d506e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame({\n",
    "    'y_test':y_test,\n",
    "    'KNN': knn_pred,\n",
    "    'Decision Tree': tree_pred,\n",
    "    'Logistic Regression': lr_pred,\n",
    "    'CNN_image':CNN_image,\n",
    "    'CNN_spec':CNN_spec,\n",
    "    'Soft Voting': soft_predictions\n",
    "})\n",
    "df_predictions.to_csv(\"pred_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f66622b-5a86-47a8-8991-d64f7b94ee4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.11069454e+00, -1.69765980e+00, -1.52708694e-01,\n",
       "         6.14388340e-01, -2.38249174e-02,  2.33575804e+01],\n",
       "       [-2.88333134e+00,  5.21275341e+00,  7.95731972e-01,\n",
       "        -1.22133450e+00, -2.14097172e+00,  3.25077789e+01],\n",
       "       [ 1.77263680e+00, -3.51509361e+00, -6.43023278e-01,\n",
       "         6.06946165e-01,  2.16479664e+00, -5.58653593e+01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831838b8-d885-4ce8-8e96-1ae8fec9bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# Assuming 'tree_clf' is your trained DecisionTreeClassifier\n",
    "export_graphviz(\n",
    "    tree_clf,\n",
    "    out_file=\"tree.dot\",\n",
    "    #feature_names=['feature1', 'feature2', 'feature3', 'etc'],  # replace with real feature names\n",
    "    #class_names=['class1', 'class2', 'class3'],  # replace with real class names\n",
    "    rounded=True,\n",
    "    filled=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45004348-e484-48d5-b264-b74cb39ecbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.96993384e-03, 7.95374525e-05, 0.00000000e+00, 3.70286625e-08,\n",
       "       8.03605042e-04, 9.96146887e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5c3e9da-1d2c-4d0e-b05c-ac376860b9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree.png'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "# Load dot file\n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "# Create a graph from dot file and render it to a file\n",
    "graph = graphviz.Source(dot_graph)\n",
    "graph.render(\"tree\", format='png', cleanup=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a3b3ca-83d4-4066-bd10-64c54ddfd275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
