{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702bd2f3-8744-4943-b69d-6198a0c51760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv(\"./stat679final/data/metadata/train_metadata.csv\")\n",
    "df_test = pd.read_csv(\"./stat679final/data/metadata/test_metadata.csv\")\n",
    "X_train, y_train = df_train.iloc[:, 0:6], df_train[\"class\"]\n",
    "# X, y = df.iloc[:, 0:6], df[\"class\"]\n",
    "X_test, y_test = df_test.iloc[:, 0:6], df_test[\"class\"]\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Instantiate the individual classifiers\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "lr_clf = LogisticRegression(max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1217a712-bde1-4ce0-b704-e6cbb5846a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard\n",
      "soft\n",
      "Hard Voting Accuracy: 0.968598429921496\n",
      "Soft Voting Accuracy: 0.9742487124356218\n"
     ]
    }
   ],
   "source": [
    "# svm_clf = SVC(probability=True)  # Enable probability for soft voting\n",
    "\n",
    "# Create a voting classifier\n",
    "voting_clf_hard = VotingClassifier(\n",
    "    estimators=[('knn', knn_clf), ('dt', tree_clf)],\n",
    "    voting='hard'\n",
    ")\n",
    "voting_clf_soft = VotingClassifier(\n",
    "    estimators=[('knn', knn_clf), ('dt', tree_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the classifiers\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "print(\"hard\")\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "print(\"soft\")\n",
    "# Make predictions and evaluate\n",
    "y_pred_hard = voting_clf_hard.predict(X_test)\n",
    "y_pred_soft = voting_clf_soft.predict(X_test)\n",
    "\n",
    "print(\"Hard Voting Accuracy:\", accuracy_score(y_test, y_pred_hard))\n",
    "print(\"Soft Voting Accuracy:\", accuracy_score(y_test, y_pred_soft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102660a4-958a-47aa-8820-666b1953cba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class PyTorchClassifierWrapper:\n",
    "    def __init__(self, model, device='cpu'):\n",
    "        self.model = model\n",
    "        self.model.to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def predict_proba(self, dataloader):\n",
    "        # Ensure the model is in evaluation mode\n",
    "        self.model.eval()\n",
    "        \n",
    "        # List to hold all batch probabilities\n",
    "        all_probabilities = []\n",
    "\n",
    "        # Loop over all batches in the dataloader\n",
    "        for X_batch in dataloader:\n",
    "            images, label = X_batch\n",
    "            # Transfer batch to the device (GPU or CPU)\n",
    "            images = images.to(self.device)\n",
    "\n",
    "            # Disable gradient computation\n",
    "            with torch.no_grad():\n",
    "                if images == 'unreadable':\n",
    "                    outputs = tensor([[ 1/3, 1/3, 1/3]])\n",
    "                else: \n",
    "                    outputs = self.model(images)\n",
    "\n",
    "            # Apply softmax to compute probabilities\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Move probabilities to CPU and convert to numpy\n",
    "            probabilities = probabilities.cpu().numpy()\n",
    "            \n",
    "            # Append batch probabilities to list\n",
    "            all_probabilities.append(probabilities)\n",
    "\n",
    "        # Concatenate all batch probabilities into a single array\n",
    "        all_probabilities = np.concatenate(all_probabilities, axis=0)\n",
    "        \n",
    "        return all_probabilities\n",
    "    def predict(self,dataloader):\n",
    "        all_predictions = []\n",
    "        for X_batch in dataloader:\n",
    "            images, label = X_batch\n",
    "            # Transfer batch to the device (GPU or CPU)\n",
    "            images = images.to(self.device)\n",
    "\n",
    "            # Disable gradient computation\n",
    "            with torch.no_grad():\n",
    "                if images == 'unreadable':\n",
    "                    outputs = tensor([[ 1/3, 1/3, 1/3]])\n",
    "                else: \n",
    "                    outputs = self.model(images)\n",
    "            max_indices = outputs.argmax(dim=-1)\n",
    "\n",
    "            # Convert indices to one-hot encoded tensor\n",
    "            predictions = F.one_hot(max_indices, num_classes=outputs.shape[-1]).cpu().numpy()\n",
    "\n",
    "            # Move probabilities to CPU and convert to numpy\n",
    "            \n",
    "            # Append batch probabilities to list\n",
    "            all_predictions.append(predictions)\n",
    "\n",
    "        # Concatenate all batch probabilities into a single array\n",
    "        all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "        \n",
    "        return all_predictions\n",
    "\n",
    "    \n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Input channels = 3 (RGB), 6 output channels, 5x5 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 13 * 13, 120)  # Adjusted for 64x64 input images\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 3)  # Output 3 classes: STAR, QSO, GALAXY\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 13 * 13)  # Flatten the tensor for the fully connected layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e65a3de-0b46-4c75-b00c-fa981aa07d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=2704, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
      ")\n",
      "it is a galaxy\n",
      "tensor([[ 3.7507, -0.3346, -4.1034]])\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN()\n",
    "model.load_state_dict(torch.load('./stat679final/model/CNN/SimpleCNN_state_dict.pth'))\n",
    "model.eval()  \n",
    "print(model)\n",
    "\n",
    "\n",
    "# Define the same transformation as during the training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Example resize, adjust to your model's input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('./stat679final/data/GALAXY/GALAXY_1.jpg')\n",
    "image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "with torch.no_grad():  # Turn off gradients for inference\n",
    "    output = model(image)\n",
    "    # Assuming classification: get the predicted class (the index of the max log-probability)\n",
    "    predicted_class = torch.argmax(output, dim=1)\n",
    "    if predicted_class.item()+1 == 1:\n",
    "      print(\"it is a galaxy\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc60b7ec-4d7b-49df-bfc3-adb002422a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=2704, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=3, bias=True)\n",
      ")\n",
      "it is a galaxy\n",
      "tensor([[ 2.8297, -1.9385, -1.7206]])\n"
     ]
    }
   ],
   "source": [
    "model_spec = SimpleCNN()\n",
    "model_spec.load_state_dict(torch.load('./stat679final/model/CNN/spec_state_dict.pth'))\n",
    "model_spec.eval()  \n",
    "print(model_spec)\n",
    "\n",
    "\n",
    "# Define the same transformation as during the training\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Example resize, adjust to your model's input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the image\n",
    "image = Image.open('./data_spec/GALAXY_spec/GALAXY_1.jpg').convert('RGB')\n",
    "image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "with torch.no_grad():  # Turn off gradients for inference\n",
    "    output = model_spec(image)\n",
    "    # Assuming classification: get the predicted class (the index of the max log-probability)\n",
    "    predicted_class = torch.argmax(output, dim=1)\n",
    "    if predicted_class.item()+1 == 1:\n",
    "        print(\"it is a galaxy\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe87412-983b-4a92-844e-cc54a2a1c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(models, datasets):\n",
    "    \"\"\"\n",
    "    对多个模型的预测概率进行平均，返回最终预测类别。\n",
    "    :param models: 包含四个模型的列表\n",
    "    :param datasets: 每个模型对应的测试数据集列表\n",
    "    :return: 最终的预测类别数组\n",
    "    \"\"\"\n",
    "    # 收集所有模型的预测概率\n",
    "    proba_lists = [model.predict_proba(data) for model, data in zip(models, datasets)]\n",
    "\n",
    "    # 计算平均预测概率\n",
    "    avg_proba = np.mean(proba_lists, axis=0)\n",
    "\n",
    "    # 选择平均概率最高的类别作为最终预测\n",
    "    final_predictions = np.argmax(avg_proba, axis=1)\n",
    "    return final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d64f48-950a-4e21-95ee-a67cacbaa12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def weighted_hard_voting(models, datasets, weights):\n",
    "    \"\"\"\n",
    "    对多个模型的预测类别进行加权硬投票，返回最终预测类别。\n",
    "    :param models: 包含四个模型的列表\n",
    "    :param datasets: 每个模型对应的测试数据集列表\n",
    "    :param weights: 每个模型在训练集上的准确率作为权重，列表形式\n",
    "    :return: 最终的预测类别数组\n",
    "    \"\"\"\n",
    "    # 收集所有模型的预测类别\n",
    "    predictions = [model.predict(data) for model, data in zip(models, datasets)]\n",
    "    \n",
    "    # 转换预测为权重计票矩阵\n",
    "    weighted_votes = np.zeros((datasets[3].shape[0], np.max(predictions) + 1))  # 假设类别从0开始\n",
    "\n",
    "    # 累加每个模型的预测权重到对应类别\n",
    "    for prediction, weight in zip(predictions, weights):\n",
    "        for i, pred in enumerate(prediction):\n",
    "            weighted_votes[i, pred] += weight\n",
    "\n",
    "    # 选择权重计票最高的类别作为最终预测\n",
    "    final_predictions = np.argmax(weighted_votes, axis=1)\n",
    "    return final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd370ae6-57a4-481f-ba32-381943e3548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model1 = PyTorchClassifierWrapper(model, device='cpu')\n",
    "pytorch_model2 = PyTorchClassifierWrapper(model_spec, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21d4f473-acaa-45f7-9e81-b36b136cbdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=3000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=3000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=3000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(X_train, y_train)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edb3bb1f-2c2d-455c-9e61-df6be47215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bef285c-2374-4459-8110-3c5ba4ab832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = pd.read_csv(\"./stat679final/data/rnk_test.csv\")\n",
    "#test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fee4b329-a9eb-4527-8434-35ca7d836491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Resize to ensure all images are the same size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # Normalize images\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da641a6-b4d6-49d3-839f-1675752ec37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels  # Store the labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        label = self.labels[idx]  # Get the label for the current image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            try:\n",
    "                image = self.transform(image)\n",
    "                return image, label  # Return both the image and the label\n",
    "            except IOError:\n",
    "                return 'unreadable', lable\n",
    "# Assuming 'class' column in image_paths_df contains labels\n",
    "img_paths = test_image['image']\n",
    "labels = test_image['class']  # Load labels from the dataframe\n",
    "\n",
    "# Initialize dataset with paths and labels\n",
    "custom_dataset = CustomImageDataset(img_paths, labels, transform=transform)\n",
    "custom_data_loader = DataLoader(custom_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "img_paths_spec = test_image['spec']\n",
    "labels = test_image['class']  # Load labels from the dataframe\n",
    "\n",
    "# Initialize dataset with paths and labels\n",
    "custom_dataset_spec = CustomImageDataset(img_paths, labels, transform=transform)\n",
    "custom_data_loader_spec = DataLoader(custom_dataset_spec, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9f8e0dc-138d-4b53-8a63-4e67e200d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn模型不需要wrapper\n",
    "models = [pytorch_model1,pytorch_model2, knn_clf,tree_clf,lr_clf]\n",
    "datasets = [custom_data_loader,custom_data_loader_spec,X_test,X_test,X_test]\n",
    "# 执行软投票\n",
    "final_predictions = soft_voting(models, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "518a0fcb-1088-4aba-9dbf-f233990d4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = [0.918, 0.9914,0.8722,0.9159]\n",
    "# # scikit-learn模型不需要wrapper\n",
    "# models = [pytorch_model1,pytorch_model2, knn_clf, tree_clf]\n",
    "# datasets = [custom_data_loader,custom_data_loader,X_test,X_test]\n",
    "# # 执行软投票\n",
    "# final_predictions = weighted_hard_voting(models, datasets,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "060aa9e6-02bc-4753-ab9e-5fd762d100f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scikit-learn模型不需要wrapper\n",
    "# models = [knn_clf, tree_clf,lr_clf]\n",
    "# datasets = [X_test,X_test,X_test]\n",
    "# # 执行软投票\n",
    "# final_predictions = soft_voting(models, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37320fc2-6022-4ba9-a143-90254fd67a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.967948397419871"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(knn_clf.predict(X_test) == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5896ea99-98f0-4a46-acfd-6ad9a91e409d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9764488224411221"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tree_clf.predict(X_test) == y_test).sum()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99490884-5256-47d5-8eab-ae712c254633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9770988549427472"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = df_test[\"class\"]\n",
    "(y_test == final_predictions).sum()/len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
